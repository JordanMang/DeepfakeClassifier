{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pksMAQk0jjCt"
      },
      "source": [
        "# XCEPTION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUns3wNpjjCw"
      },
      "source": [
        "## Opening Remarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpItWJg6wj9Y"
      },
      "source": [
        "After a bit of time trying to create confusion matrix's based on my model I started running into some problems and to work around those issues I had to recreate the structure of my pipeline to include generators and this was a learning journey for sure. XCEPTION is another premade model that I am hoiping to use to gain a couple more points in my accuracy model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "keIiLw3fTC5o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from tensorflow import keras\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, Sequential\n",
        "from tensorflow.keras import models, layers, optimizers, regularizers\n",
        "# from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6GNzF4VjrCO",
        "outputId": "26d42d6e-613f-408f-8d24-39e2cf9238d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZxouzLH4jjCz"
      },
      "outputs": [],
      "source": [
        "# using ImageDataGenerator to rescale all images \n",
        "train_datagen = ImageDataGenerator(rescale=1./256)\n",
        "val_datagen = ImageDataGenerator(rescale=1./256)\n",
        "test_datagen = ImageDataGenerator(rescale=1./256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XZmh89aOtD3",
        "outputId": "d8cfeebe-2065-494e-fd27-bdb8b84433da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19862 files belonging to 2 classes.\n",
            "Found 6208 files belonging to 2 classes.\n",
            "Found 4965 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Data_NEW/train')\n",
        "test = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Data_NEW/test')\n",
        "val = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/Data_NEW/val')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Frgs5SkljjC0",
        "outputId": "60da3337-74fe-44be-ff61-15bff599867e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19862 images belonging to 2 classes.\n",
            "Found 4965 images belonging to 2 classes.\n",
            "Found 6208 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = val_datagen.flow_from_directory('/content/drive/MyDrive/Data_NEW/train',\n",
        "                                                        target_size=(256, 256),\n",
        "                                                        batch_size=32,\n",
        "                                                        color_mode='rgb',\n",
        "                                                        class_mode='binary')\n",
        "validation_generator = val_datagen.flow_from_directory('/content/drive/MyDrive/Data_NEW/val',\n",
        "                                                        target_size=(256, 256),\n",
        "                                                        batch_size=10,\n",
        "                                                        color_mode='rgb',\n",
        "                                                        class_mode='binary')\n",
        "test_generator = test_datagen.flow_from_directory('/content/drive/MyDrive/Data_NEW/test',\n",
        "                                                  target_size=(256, 256),\n",
        "                                                  batch_size=1,\n",
        "                                                  color_mode='rgb',\n",
        "                                                  class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "88todEzgq_qQ"
      },
      "outputs": [],
      "source": [
        "test_data, test_labels = next (test_generator)\n",
        "train_data, train_labels = next (train_generator)\n",
        "val_data, val_labels = next (validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RFulpsYT5kHE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be57ea5c-e8a0-41a7-b90b-43f9c6f1bc80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83689472/83683744 [==============================] - 2s 0us/step\n",
            "83697664/83683744 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "xception = tf.keras.applications.Xception(\n",
        "                                            include_top=False,     \n",
        "                                            weights='imagenet',          \n",
        "                                            classifier_activation='sigmoid',     \n",
        "                                            input_shape=(256, 256, 3), )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VoXG5p2gmF9",
        "outputId": "2ec1d07c-3e25-4d5e-be56-341eb59ba0c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " xception (Functional)       (None, 8, 8, 2048)        20861480  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 131072)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 131073    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,992,553\n",
            "Trainable params: 20,938,025\n",
            "Non-trainable params: 54,528\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "xception,\n",
        "layers.Flatten(),\n",
        "layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=optimizers.Adam(learning_rate=0.00001),\n",
        "              loss=tf.losses.BinaryCrossentropy(),\n",
        "              metrics='accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4M7xs3z2gsUd",
        "outputId": "20fce397-f122-4d3e-9a48-254d7a534681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 614s 6s/step - loss: 0.0729 - accuracy: 0.9753 - val_loss: 0.0801 - val_accuracy: 0.9734\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 532s 5s/step - loss: 0.0810 - accuracy: 0.9727 - val_loss: 0.0750 - val_accuracy: 0.9736\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 457s 5s/step - loss: 0.0643 - accuracy: 0.9825 - val_loss: 0.0614 - val_accuracy: 0.9793\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 384s 4s/step - loss: 0.0431 - accuracy: 0.9891 - val_loss: 0.0539 - val_accuracy: 0.9821\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 316s 3s/step - loss: 0.0352 - accuracy: 0.9897 - val_loss: 0.0503 - val_accuracy: 0.9839\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_generator,\n",
        "                    steps_per_epoch=100,\n",
        "                    epochs=5,  # Number of epochs\n",
        "                    validation_data=validation_generator,\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2nkHzU6Lg5NI"
      },
      "outputs": [],
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fSDjYwskg_ly"
      },
      "outputs": [],
      "source": [
        "# Get precision, recall, and accuracy for test batch set\n",
        "for batch in test.as_numpy_iterator(): \n",
        "    X, y = batch\n",
        "    yhat = model.predict(X)\n",
        "    pre.update_state(y, yhat)\n",
        "    re.update_state(y, yhat)\n",
        "    acc.update_state(y, yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCEkeSt4ro5z",
        "outputId": "aac289e3-157b-4570-dc2b-779eaca80e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.5087265968322754, Recall: 0.9958873987197876, Accuracy: 0.5082151889801025\n"
          ]
        }
      ],
      "source": [
        "print(f'Precision: {pre.result()}, Recall: {re.result()}, Accuracy: {acc.result()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgM-wPKQjjC4"
      },
      "source": [
        "# Results of VGG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5sEeiHP21Yi"
      },
      "source": [
        "VGG:Precision: 0.9582728743553162, Recall: 0.835495114326477, Accuracy: 0.8977126479148865 (2 EPOCHS)\n",
        "<br>VGG:Precision: Precision: 0.9752442836761475, Recall: 0.9471685886383057, Accuracy: 0.9608569741249084\n",
        "(6 EPOCHS)\n",
        "<br>VGG:Precision: Precision: 0.9539697170257568, Recall: 0.9769060611724854, Accuracy: 0.9642397165298462\n",
        "(8 EPOCHS)\n",
        "<br>VGG:Precision: Precision: 0.9901024103164673, Recall: 0.9177475571632385, Accuracy: 0.953447163105011\n",
        "(10 EPOCHS)\n",
        "<br> VGG_COMP: Precision: 0.9824896454811096, Recall: 0.9762733578681946, Accuracy: 0.9790592789649963 (7 EPOCHS)\n",
        "<br> VGG (REVAMP): Precision: 0.6386809349060059, Recall: 0.9987345933914185, Accuracy: 0.7116623520851135 (7 EPOCHS)\n",
        "<br> VGG (REVAMP): Precision: 0.7617433667182922, Recall: 0.9952546954154968, Accuracy: 0.8390786051750183 (10 EPOCHS)\n",
        "<br>Precision: 0.7409582138061523, Recall: 0.9981018900871277, Accuracy: 0.8213595151901245 - 11 EPOCHS\n",
        "<br>Precision: 0.7332867383956909, Recall: 0.9958873987197876, Accuracy: 0.813466489315033 - 12 EPOCHS\n",
        "<br>XCEPTION: Precision: 0.5087947845458984, Recall: 0.9882948398590088, Accuracy: 0.5082151889801025 - 5\n",
        "<br>XCEPTION: Precision: 0.5087265968322754, Recall: 0.9958873987197876, Accuracy: 0.5082151889801025 - 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fagFNMDYjjC5"
      },
      "source": [
        "# Take Aways"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nY7TpjejjC5"
      },
      "source": [
        "I thought that XCEPTION would do a little better than the VGG but that doesn't seem to be the case? I only base this off the fact that Stanford used it in their deepfake model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPkhNe0ajjC7"
      },
      "source": [
        "# Create Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "dotRYoT7QDjo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to show confusion matrix \n",
        "##from sklearn\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "whQDAPg1QFNq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = val_datagen.flow_from_directory('/content/drive/MyDrive/Data_NEW/val',\n",
        "                                                        target_size=(256, 256),\n",
        "                                                        batch_size=1000,\n",
        "                                                        color_mode='rgb',\n",
        "                                                        class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Not2uPIQXKdg",
        "outputId": "c9f9e5dc-a4e1-48f5-a99c-22cf8c416940"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4965 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data, val_labels = next (validation_generator)"
      ],
      "metadata": {
        "id": "n0tFxNEdXQWO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(val_data) > 0.5).astype(\"int32\")\n",
        "cm = confusion_matrix(y_true= val_labels, y_pred=y_pred)  "
      ],
      "metadata": {
        "id": "cSmdEVK8QIq6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "cm_labels = ['Unaltered','Deepfake']\n",
        "plot_confusion_matrix(cm=cm, classes=cm_labels, title='XCEPTION');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "sCO6yJ7DQOXA",
        "outputId": "4eccdee4-bc6e-40f6-a24f-1f769a0b3867"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix, without normalization\n",
            "[[492   5]\n",
            " [ 12 491]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
